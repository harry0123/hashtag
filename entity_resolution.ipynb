{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "DATA_PATH = \"/home/ubuntu/hashtag/\"\n",
      "\n",
      "tweets = pd.read_csv(DATA_PATH+'tweets.csv', low_memory=False).drop_duplicates()\n",
      "\n",
      "#print tweets.info()\n",
      "tweets = tweets[['id_str', 'created_at', 'text', 'retweet_count', 'hashtags', 'lat', 'lng']]\n",
      "print tweets.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 206672 entries, 0 to 206671\n",
        "Data columns (total 7 columns):\n",
        "id_str           206672  non-null values\n",
        "created_at       206672  non-null values\n",
        "text             206672  non-null values\n",
        "retweet_count    206672  non-null values\n",
        "hashtags         84666  non-null values\n",
        "lat              7012  non-null values\n",
        "lng              6273  non-null values\n",
        "dtypes: float64(1), int64(2), object(4)None\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = [line.rstrip() for line in open(DATA_PATH + \"stopwords.txt\", 'r')] # Load from file\n",
      "quickbrownfox = \"A quick brown fox jumps over the lazy dog\"\n",
      "import re\n",
      "\n",
      "def simple_tokenize(string):\n",
      "    split_regex = r'\\W+'\n",
      "    return filter(None, re.split(split_regex, string.lower()))\n",
      "\n",
      "def tokenize(string):\n",
      "    return [word for word in simple_tokenize(string) if word not in stopwords]\n",
      "\n",
      "print tokenize(quickbrownfox) # Should give ['quick', 'brown', ... ]\n",
      "\n",
      "print tweets[tweets['id_str']==454479340789837824].text.item()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']\n",
        "\u201c@StyleList: An outfit for each day of #Coachella's first weekend: http://t.co/5xGyX7QfH3 http://t.co/ZOZZc8GF5F\u201d\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets['text'] = tweets['text'].apply(tokenize)\n",
      "print tweets[tweets['id_str']==454479340789837824].text.item()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['stylelist', 'outfit', 'day', 'coachella', 'first', 'weekend', 'http', 'co', '5xgyx7qfh3', 'http', 'co', 'zozzc8gf5f']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "def tf(tokens):\n",
      "    total = float(len(tokens))\n",
      "    count = Counter()\n",
      "    for word in tokens:\n",
      "        count[word] += 1\n",
      "    count = dict(count)\n",
      "    for word in count:\n",
      "        count[word] = float(count[word]) / total\n",
      "    return count\n",
      "\n",
      "tweets['tf'] = tweets['text'].apply(tf)\n",
      "#print tweets.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "               id_str                 created_at  \\\n",
        "0  454479571979481088  2014-04-11 04:42:28+00:00   \n",
        "1  454479532058099713  2014-04-11 04:42:18+00:00   \n",
        "2  454479521119363072  2014-04-11 04:42:16+00:00   \n",
        "3  454479492522598401  2014-04-11 04:42:09+00:00   \n",
        "4  454479396254928897  2014-04-11 04:41:46+00:00   \n",
        "\n",
        "                                                text  retweet_count  \\\n",
        "0  [time, get, life, together, head, desert, coac...              0   \n",
        "1  [rt, freddyrivera, first, coachella, 2009, sir...              1   \n",
        "2            [wanna, go, coachella, bad, bucketlist]              0   \n",
        "3  [everyone, talking, coachella, makes, want, go...              0   \n",
        "4  [rt, stylelist, outfit, day, coachella, first,...              5   \n",
        "\n",
        "    hashtags  lat  lng                                                 tf  \n",
        "0  Coachella  NaN  NaN  {u'life': 0.111111111111, u'get': 0.1111111111...  \n",
        "1  Coachella  NaN  NaN  {u'rt': 0.0769230769231, u'freddyrivera': 0.07...  \n",
        "2  coachella  NaN  NaN  {u'go': 0.2, u'wanna': 0.2, u'bad': 0.2, u'buc...  \n",
        "3  coachella  NaN  NaN  {u'even': 0.125, u'everyone': 0.125, u'sobbing...  \n",
        "4  Coachella  NaN  NaN  {u'rt': 0.0769230769231, u'stylelist': 0.07692...  \n",
        "\n",
        "[5 rows x 8 columns]\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}