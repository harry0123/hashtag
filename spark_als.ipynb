{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "a = open('handle_to_id.p', 'rb')\n",
      "b = open('sn_to_userid.p', 'rb')\n",
      "c = open('total_set.p', 'rb')\n",
      "handle_to_id = pickle.load(a)\n",
      "sn_to_id = pickle.load(b)\n",
      "total_set = pickle.load(c)\n",
      "a.close()\n",
      "b.close()\n",
      "c.close()\n",
      "\n",
      "print len(handle_to_id)\n",
      "print len(sn_to_id)\n",
      "print len(total_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "194\n",
        "14808\n",
        "90613\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "path_to_spark = '/home/ubuntu/datascience-sp14/hw3/spark-0.9.1-bin-cdh4'\n",
      "os.environ['SPARK_HOME'] = path_to_spark\n",
      "\n",
      "# Set the python path so that we know where to find the pyspark files.\n",
      "import sys\n",
      "path_to_pyspark = os.path.join(path_to_spark, \"python\")\n",
      "sys.path.insert(0, path_to_pyspark)\n",
      "\n",
      "from pyspark import SparkContext\n",
      "# You can set the app name to whatever you want; this just affects what\n",
      "# will show up in the UI.\n",
      "app_name = \"i<3datascience\"\n",
      "sc = SparkContext(\"local\", app_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "all_data = sc.parallelize(total_set)\n",
      "print all_data.cache().count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "90613\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = sc.parallelize(total_set)\n",
      "training = all_data.filter(lambda x: x[0] % 10 < 6)\n",
      "validation = all_data.filter(lambda x: x[0] % 10 >= 6 and x[0] % 10 < 8)\n",
      "test = all_data.filter(lambda x: x[0] % 10 >= 8)\n",
      "\n",
      "print all_data.count()\n",
      "print training.count()\n",
      "print validation.count()\n",
      "print test.count()\n",
      "#print \"Training: %s, validation: %s, test: %s\" % (training.count(), validation.count(), test.count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "90613\n",
        "53799"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17143"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19671"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[(5939, 110, 0), (9762, 104, 0), (11063, 134, 0), (3993, 186, 0), (2334, 7, 0)]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "def compute_error(predicted, actual):\n",
      "    \"\"\" Compute the root mean squared error between predicted and actual.\n",
      "    \n",
      "    Params:\n",
      "      predicted: An RDD of predicted ratings for each movie and each user where each entry is in the form (user, movie, rating).\n",
      "      actual: An RDD of actual ratings where each entry is in the form (user, movie, rating).\n",
      "    \"\"\"\n",
      "    # Make each RDD in the format ((user, movie), rating) so we can easily join them together.\n",
      "    predicted_reformatted = predicted.map(lambda x: ((x[0], x[1]), x[2]))\n",
      "    actual_reformatted = actual.map(lambda x: ((x[0], x[1]), x[2]))\n",
      "    predicted_and_actual = predicted_reformatted.join(actual_reformatted)\n",
      "    squared_errors = predicted_and_actual.map(lambda x: (x[1][1] - x[1][0])**2)\n",
      "    total_error = squared_errors.reduce(lambda x,y: x + y)\n",
      "    num_ratings = squared_errors.count()\n",
      "    return math.sqrt(total_error * 1.0 / num_ratings)\n",
      "\n",
      "test_predicted = sc.parallelize([\n",
      "    (1, 1, 5),\n",
      "    (1, 2, 3),\n",
      "    (1, 3, 4),\n",
      "    (2, 1, 3),\n",
      "    (2, 2, 2),\n",
      "    (2, 3, 4)])\n",
      "test_actual = sc.parallelize([\n",
      "     (1, 2, 3),\n",
      "     (1, 3, 5),\n",
      "     (2, 1, 5),\n",
      "     (2, 2, 1)])\n",
      "print \"Error for test datasets: %s\" % compute_error(test_predicted, test_actual)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error for test datasets: 1.22474487139\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print formatted_training.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(9762, 104, 0), (11063, 134, 0), (3993, 186, 0), (2334, 7, 0), (2130, 55, 0)]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.recommendation import ALS\n",
      "\n",
      "formatted_training = training.map(lambda x: (x[0], x[1], x[2])).cache()\n",
      "validation_for_predict = validation.map(lambda x: (x[0], x[1])).cache()\n",
      "validation_for_error = validation.map(lambda x: (x[0], x[1], x[2]))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ranks = [1, 4, 8, 12, 16]\n",
      "\n",
      "min_error = float(\"inf\")\n",
      "best_rank = -1\n",
      "for rank in ranks:\n",
      "    model = ALS.train(formatted_training, rank)\n",
      "    predicted_ratings = model.predictAll(validation_for_predict)\n",
      "    print predicted_ratings.take(5)\n",
      "    #error = compute_error(predicted_ratings, validation_for_error)\n",
      "    #print rank, error\n",
      "    #if error < min_error:\n",
      "    #    min_error = error\n",
      "    #    best_rank = rank\n",
      "\n",
      "print \"The best model was trained with rank %s\" % best_rank"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The best model was trained with rank -1\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}